{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import extract_frames_realtime\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from ultralyticsplus import YOLO, render_result\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to ultralyticsplus\\yolov8n.pt...\n",
      "100%|██████████| 6.23M/6.23M [01:01<00:00, 106kB/s] \n"
     ]
    }
   ],
   "source": [
    "model = YOLO('ultralyticsplus/yolov8n')\n",
    "\n",
    "# set model parameters\n",
    "model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "model.overrides['max_det'] = 1000  # maximum number of detections per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_writer(video_cap, output_filename):\n",
    "\n",
    "    # grab the width, height, and fps of the frames in the video stream.\n",
    "    frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # initialize the FourCC and a video writer object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    writer = cv2.VideoWriter(output_filename, fourcc, fps,\n",
    "                             (frame_width, frame_height))\n",
    "\n",
    "    return writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.43  Python-3.11.4 torch-2.0.1 CUDA:0 (NVIDIA GeForce GTX 1050, 4096MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at C:\\Users\\circleci\\project\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nQuantizedCPU: registered at C:\\Users\\circleci\\project\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:280 [backend fallback]\nNamed: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradOther: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:30 [backend fallback]\nAutogradCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:34 [backend fallback]\nAutogradCUDA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:42 [backend fallback]\nAutogradXLA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:46 [backend fallback]\nAutogradMPS: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:54 [backend fallback]\nAutogradXPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:38 [backend fallback]\nAutogradHPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradLazy: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:50 [backend fallback]\nAutogradMeta: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:58 [backend fallback]\nTracer: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:815 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1073 [backend fallback]\nVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:148 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret:\n\u001b[0;32m     18\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m detections \u001b[39m=\u001b[39m model(frame)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m detections\u001b[39m.\u001b[39mboxes\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtolist():\n\u001b[0;32m     23\u001b[0m     confidence \u001b[39m=\u001b[39m data[\u001b[39m4\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\thinl\\scoop\\apps\\mambaforge\\current\\envs\\cnn\\Lib\\site-packages\\ultralytics\\yolo\\engine\\model.py:102\u001b[0m, in \u001b[0;36mYOLO.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, source\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(source, stream, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\thinl\\scoop\\apps\\mambaforge\\current\\envs\\cnn\\Lib\\site-packages\\ultralytics\\yolo\\engine\\model.py:202\u001b[0m, in \u001b[0;36mYOLO.predict\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m get_cfg(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39margs, overrides)\n\u001b[0;32m    201\u001b[0m is_cli \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39margv[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39myolo\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m sys\u001b[39m.\u001b[39margv[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39multralytics\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[1;32mc:\\Users\\thinl\\scoop\\apps\\mambaforge\\current\\envs\\cnn\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\thinl\\scoop\\apps\\mambaforge\\current\\envs\\cnn\\Lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py:116\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model)\n\u001b[0;32m    115\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream_inference(source, model))\n",
      "File \u001b[1;32mc:\\Users\\thinl\\scoop\\apps\\mambaforge\\current\\envs\\cnn\\Lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py:175\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39m# postprocess\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt[\u001b[39m2\u001b[39m]:\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpostprocess(preds, im, im0s)\n\u001b[0;32m    176\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks(\u001b[39m'\u001b[39m\u001b[39mon_predict_postprocess_end\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    178\u001b[0m \u001b[39m# visualize, save, write results\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thinl\\scoop\\apps\\mambaforge\\current\\envs\\cnn\\Lib\\site-packages\\ultralytics\\yolo\\v8\\detect\\predict.py:23\u001b[0m, in \u001b[0;36mDetectionPredictor.postprocess\u001b[1;34m(self, preds, img, orig_img)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpostprocess\u001b[39m(\u001b[39mself\u001b[39m, preds, img, orig_img):\n\u001b[1;32m---> 23\u001b[0m     preds \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mnon_max_suppression(preds,\n\u001b[0;32m     24\u001b[0m                                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mconf,\n\u001b[0;32m     25\u001b[0m                                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49miou,\n\u001b[0;32m     26\u001b[0m                                     agnostic\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49magnostic_nms,\n\u001b[0;32m     27\u001b[0m                                     max_det\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mmax_det,\n\u001b[0;32m     28\u001b[0m                                     classes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mclasses)\n\u001b[0;32m     30\u001b[0m     results \u001b[39m=\u001b[39m []\n\u001b[0;32m     31\u001b[0m     \u001b[39mfor\u001b[39;00m i, pred \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(preds):\n",
      "File \u001b[1;32mc:\\Users\\thinl\\scoop\\apps\\mambaforge\\current\\envs\\cnn\\Lib\\site-packages\\ultralytics\\yolo\\utils\\ops.py:245\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[1;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh)\u001b[0m\n\u001b[0;32m    243\u001b[0m c \u001b[39m=\u001b[39m x[:, \u001b[39m5\u001b[39m:\u001b[39m6\u001b[39m] \u001b[39m*\u001b[39m (\u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m agnostic \u001b[39melse\u001b[39;00m max_wh)  \u001b[39m# classes\u001b[39;00m\n\u001b[0;32m    244\u001b[0m boxes, scores \u001b[39m=\u001b[39m x[:, :\u001b[39m4\u001b[39m] \u001b[39m+\u001b[39m c, x[:, \u001b[39m4\u001b[39m]  \u001b[39m# boxes (offset by class), scores\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m i \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mnms(boxes, scores, iou_thres)  \u001b[39m# NMS\u001b[39;00m\n\u001b[0;32m    246\u001b[0m i \u001b[39m=\u001b[39m i[:max_det]  \u001b[39m# limit detections\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[39mif\u001b[39;00m merge \u001b[39mand\u001b[39;00m (\u001b[39m1\u001b[39m \u001b[39m<\u001b[39m n \u001b[39m<\u001b[39m \u001b[39m3E3\u001b[39m):  \u001b[39m# Merge NMS (boxes merged using weighted mean)\u001b[39;00m\n\u001b[0;32m    248\u001b[0m     \u001b[39m# update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thinl\\scoop\\apps\\mambaforge\\current\\envs\\cnn\\Lib\\site-packages\\torchvision\\ops\\boxes.py:41\u001b[0m, in \u001b[0;36mnms\u001b[1;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[0;32m     39\u001b[0m     _log_api_usage_once(nms)\n\u001b[0;32m     40\u001b[0m _assert_has_ops()\n\u001b[1;32m---> 41\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mtorchvision\u001b[39m.\u001b[39;49mnms(boxes, scores, iou_threshold)\n",
      "File \u001b[1;32mc:\\Users\\thinl\\scoop\\apps\\mambaforge\\current\\envs\\cnn\\Lib\\site-packages\\torch\\_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at C:\\Users\\circleci\\project\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nQuantizedCPU: registered at C:\\Users\\circleci\\project\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:280 [backend fallback]\nNamed: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradOther: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:30 [backend fallback]\nAutogradCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:34 [backend fallback]\nAutogradCUDA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:42 [backend fallback]\nAutogradXLA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:46 [backend fallback]\nAutogradMPS: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:54 [backend fallback]\nAutogradXPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:38 [backend fallback]\nAutogradHPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradLazy: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:50 [backend fallback]\nAutogradMeta: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:58 [backend fallback]\nTracer: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:815 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1073 [backend fallback]\nVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:148 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "video_path = \"data/traffic.mp4\"\n",
    "\n",
    "capture = cv2.VideoCapture(video_path)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)\n",
    "capture_fps = round(capture.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "current_frame = 0\n",
    "\n",
    "writer = create_video_writer(capture, \"output.mp4\")\n",
    "\n",
    "while capture.isOpened():\n",
    "    start = datetime.now()\n",
    "    \n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    detections = model(frame)[0]\n",
    "    \n",
    "    for data in detections.boxes.data.tolist():\n",
    "        confidence = data[4]\n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "        cv2.rectangle(frame, (xmin, ymin) , (xmax, ymax), (255, 50, 30), 2)\n",
    "\n",
    "    end = datetime.now()\n",
    "    elapsed = (end - start).total_seconds()\n",
    "    \n",
    "    print(f\"Time elapsed for processing 1 frame: {elapsed * 1000:.0f}ms\")\n",
    "\n",
    "    fps = f\"FPS: {1 / elapsed:.2f}\"\n",
    "    cv2.putText(frame, fps, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (30, 50, 255), 8)\n",
    "    \n",
    "    # cv2_imshow(frame)\n",
    "    writer.write(frame)\n",
    "    \n",
    "    current_frame += 1\n",
    "\n",
    "    if current_frame == 300:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "capture.release()\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = 0\n",
    "# for frame in frame_gen:\n",
    "#     plt.imshow(frame, interpolation=\"bilinear\")\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "#     index += 1\n",
    "\n",
    "#     if index == 5:\n",
    "#         break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
